<!DOCTYPE html>
<html>
<head>
    <title>Mov&#xAD;ing AI ethics be&#xAD;yond guide&#xAD;lines - PressReader</title>
    <meta name="description" content="The re&#xAD;cent row over a lead&#xAD;ing re&#xAD;searcher&#x2019;s de&#xAD;par&#xAD;ture from Google raises ques&#xAD;tions about the role and re&#xAD;mit of AI ethics teams and the in&#xAD;ad&#xAD;e&#xAD;quacy of frame&#xAD;works to deal with mo&#xAD;ral com&#xAD;plex&#xAD;i&#xAD;ties">
    <meta content="magazines, newspapers, digital news, reading, news, breaking news, newspaper online" name="keywords">
    <meta name="Robots" content="NOARCHIVE,NOODP">
    <meta charset="UTF-8">
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
    <link rel="canonical" href="/singapore/the-straits-times/20201216/281934545540152" />


    <style>
        li {
            margin: 1em 0;
        }
        img {
            max-width: 100%;
        }
        p, h1, h2, h3 {
            max-width: 100%;
        }
    </style>
</head>
<body>
    <div>
        

<article>
    <h1>Mov&#xAD;ing AI ethics be&#xAD;yond guide&#xAD;lines</h1>
    <h2>The re&#xAD;cent row over a lead&#xAD;ing re&#xAD;searcher&#x2019;s de&#xAD;par&#xAD;ture from Google raises ques&#xAD;tions about the role and re&#xAD;mit of AI ethics teams and the in&#xAD;ad&#xAD;e&#xAD;quacy of frame&#xAD;works to deal with mo&#xAD;ral com&#xAD;plex&#xAD;i&#xAD;ties</h2>
    <section>
        <a href="/singapore/the-straits-times/textview" title="The Straits Times">The Straits Times</a>
        - <a href="/singapore/the-straits-times/20201216/textview" title="The Straits Times - 2020-12-16"><time>2020-12-16</time></a>
        - <span>OPINION</span>
        - <span role="byline">Lim Sun Sun and Jef&#xAD;frey Chan Kok Hui stopin&#xAD;ion@sph.com.sg&#xD;&#xA;Lim Sun Sun is pro&#xAD;fes&#xAD;sor of com&#xAD;mu&#xAD;ni&#xAD;ca&#xAD;tion and tech&#xAD;nol&#xAD;ogy and</span>
    </section>

    <p>The de­par­ture of ar­ti­fi­cial in­tel­li­gence (AI) re­searcher</p>
    <p>Timnit Ge­bru from Google un­der con­tro­ver­sial cir­cum­stances has raised dis­com­fit­ing ques­tions about the com­pany’s stance on AI ethics. It has also re­vealed the chal­lenges of prac­tis­ing AI ethics on the front line of this field.</p>
    <p>Dr Ge­bru, who was co-lead of Google’s Eth­i­cal AI team, had earned wide­spread ac­claim for her ear­lier work high­light­ing that AI fa­cial recog­ni­tion was less ca­pa­ble of iden­ti­fy­ing women and peo­ple of colour, thereby per­pet­u­at­ing dis­crim­i­na­tion if unchecked.</p>
    <p>Her al­leged dis­missal from Google was ap­par­ently trig­gered by her lat­est re­search pa­per ques­tion­ing in­her­ent bi­ases in large mod­els used to train al­go­rithms for lan­guage pro­cess­ing.</p>
    <p>She also high­lighted the stag­ger­ing en­vi­ron­men­tal costs of train­ing such mod­els, given the con­sid­er­able com­puter pro­cess­ing power and elec­tric­ity in­volved.</p>
    <p>She cited pre­vi­ous re­search that had found that train­ing one lan­guage model gen­er­ated as much car­bon diox­ide as the life­time out­put of five av­er­age Amer­i­can cars.</p>
    <p>Dr Ge­bru as­serts that she was pres­sured by higher-ups in the com­pany to re­tract the pa­per from a forth­com­ing re­search con­fer­ence or to re­move the Google em­ploy­ees’ names from it.</p>
    <p>In re­sponse, chief ex­ec­u­tive Sun­dar Pichai stated in a com­pany-wide memo that Google should seek to im­prove the pro­cesses lead­ing to her dis­missal and framed it as a fail­ure to pro­tect the rights of a black, fe­male mi­nor­ity em­ployee, but did not ad­dress the is­sue of her re­search be­ing cen­sored.</p>
    <p>Thou­sands of Google em­ploy­ees and in­di­vid­u­als from other or­gan­i­sa­tions have since en­dorsed an open let­ter ex­press­ing sup­port for Dr Ge­bru and the pub­lic pres­sure con­tin­ues to mount.</p>
    <p>DEAL­ING WITH DILEM­MAS</p>
    <p>This un­for­tu­nate episode that is far from re­solved holds in­ter­est­ing lessons for AI ethics. That a tech­nol­ogy be­he­moth such as Google even has an AI ethics team is note­wor­thy in and of it­self.</p>
    <p>It un­der­scores how so­ci­ety’s in­ten­si­fy­ing de­ploy­ment of AI has un­leashed an ex­pand­ing litany of eth­i­cal dilem­mas around au­toma­tion, datafi­ca­tion and sur­veil­lance that tech­nol­ogy com­pa­nies must grap­ple with.</p>
    <p>While it is taken for granted that large com­pa­nies must have fi­nance, le­gal, mar­ket­ing and hu­man re­source de­part­ments, our tech­nol­o­gis­ing world does in­deed ne­ces­si­tate that com­pa­nies also hire ethics teams to pro­vide guid­ance on is­sues re­lat­ing to mo­ral re­spon­si­bil­ity and civic duty.</p>
    <p>But this then begs the ques­tion as to the roles and re­mit of such ethics teams.</p>
    <p>Given that ethics is about the morally good life, one that is to be re­flected in our AI mi­lieu, then the cru­cial mat­ter of how to de­fine the or­gan­i­sa­tional role, dis­cre­tions and safety net of pro­fes­sional ethi­cists tak­ing af­ter Dr Ge­bru re­mains an out­stand­ing task.</p>
    <p>With the far-reach­ing im­pact AI has on our ev­ery­day lives, AI ethics teams bear the colos­sal bur­den of en­sur­ing that this tech­nol­ogy is safe and fair.</p>
    <p>AI-pow­ered al­go­rithms in­creas­ingly make many high-stakes de­ci­sions with po­ten­tially se­ri­ous con­se­quences for lives and so­ci­ety – from met­ing out le­gal penal­ties to qual­i­fy­ing for a loan to land­ing a job.</p>
    <p>While AI tech­nolo­gies present clear ben­e­fits, they can nev­er­the­less bring about dif­fer­ent harms. These harms do not only in­clude the di­rect harms man­i­fested in ma­li­cious ad­ver­sar­ial at­tacks and dis­in­for­ma­tion, they also ex­tend to the in­di­rect harms per­ceived when or­gan­i­sa­tions and so­ci­eties fail to check data bi­ases or nu­anced dis­crim­i­na­tion when us­ing AI tools.</p>
    <p>AI ethics teams like Dr Ge­bru’s must there­fore weigh the ben­e­fits and harms in­tro­duced by AI pro­cesses so as to flag im­me­di­ate im­pli­ca­tions for their com­pany, but also to cau­tion against long-term reper­cus­sions for hu­man­ity at large.</p>
    <p>In prac­tice, there­fore, if such ethics teams are to be more than a to­ken of the com­pany’s cor­po­rate so­cial re­spon­si­bil­ity, are they to serve as the prover­bial con­science of the or­gan­i­sa­tion and rein it in when it wades into eth­i­cal grey ar­eas?</p>
    <p>Or is their job to ed­u­cate col­leagues on the po­ten­tial eth­i­cal pit­falls they could land in, and thereby im­bue in their en­gi­neers and de­sign­ers an in­stinc­tive ap­pre­ci­a­tion for their eth­i­cal bur­dens? Or per­haps their key func­tion is to de­velop eth­i­cal guide­lines for the or­gan­i­sa­tion as it forges ground­break­ing in­no­va­tions with­out eth­i­cal prece­dents, and then to clar­ify and set­tle eth­i­cal con­flicts that may re­sult?</p>
    <p>IN­AD­E­QUATE MOD­ELS</p>
    <p>There is in fact no lack of AI ethics guide­lines or model frame­works to­day. In an im­por­tant study eval­u­at­ing AI ethics guide­lines, Dr Thilo Ha­gen­dorff from the Univer­sity of Tue­bin­gen in Ger­many counted at least 22 ma­jor eth­i­cal guide­lines in the world.</p>
    <p>And this num­ber is surely set to rise with the re­cent in­tro­duc­tion of the Cy­berspace Ad­min­is­tra­tion of China’s guide­lines on data col­lec­tion and Sin­ga­pore’s evolv­ing AI Ethics And Gov­er­nance Body Of Knowl­edge frame­work.</p>
    <p>How­ever, crit­i­cisms of such ethics guide­lines also abound.</p>
    <p>They range from their in­ef­fec­tive­ness be­cause of in­ad­e­quate en­force­ment, to the ne­glect of fem­i­nist eth­i­cal prin­ci­ples of care and eco­log­i­cal con­cerns when de­vel­op­ing these guide­lines. Fur­ther­more, stat­ing clear eth­i­cal prin­ci­ples and val­ues up­front does not al­ways re­sult in un­am­bigu­ously eth­i­cal out­comes.</p>
    <p>Con­sider an ex­am­ple from the Euro­pean Com­mis­sion’s in­flu­en­tial Ethics Guide­lines For Trust­wor­thy AI pub­lished last year. Four eth­i­cal prin­ci­ples, namely, “Re­spect for hu­man au­ton­omy”, “Pre­ven­tion of harm”, “Fair­ness” and “Ex­pli­ca­bil­ity”, un­der­gird this guide­line.</p>
    <p>Nev­er­the­less, to pre­vent harm some­times, hu­man au­ton­omy may have to be vi­o­lated – for in­stance, when pre­dic­tive polic­ing aims to re­duce crime through con­stant sur­veil­lance that im­pinges on in­di­vid­ual pri­vacy and free­dom.</p>
    <p>These guide­lines nei­ther in­form AI de­vel­op­ers of how to trans­late eth­i­cal prin­ci­ples into math­e­mat­i­cal func­tions, nor how to make the most eth­i­cal trade-off be­tween con­test­ing prin­ci­ples in their mod­els.</p>
    <p>In other words, these guide­lines can­not set­tle con­flicts of eth­i­cal prin­ci­ples and val­ues when they clash. Only in­di­vid­u­als and or­gan­i­sa­tions will­ing to em­body these eth­i­cal guide­lines, and to trans­form them into ac­tion­able thoughts and deeds, can do that.</p>
    <p>These are tasks that AI ethics teams alone can­not un­der­take, es­pe­cially if they are not ac­corded some mod­icum of pro­tec­tion and se­cu­rity when draw­ing out in­con­ve­nient truths and im­pos­ing con­straints that no con­scionable or­gan­i­sa­tion should vi­o­late.</p>
    <p>BUILD­ING ETH­I­CAL SCAFFOLDS UP­STREAM</p>
    <p>Build­ing ro­bust eth­i­cal scaffolds up­stream is an­other ur­gent en­deav­our to pur­sue.</p>
    <p>Prin­ci­pally, we must en­sure that our next gen­er­a­tion of tech­nol­ogy pro­fes­sion­als are fully cog­nisant of the mo­ral com­plex­i­ties of their work.</p>
    <p>They must learn to ap­pre­ci­ate how their apps, codes, pro­grams, soft­ware and struc­tures can have large so­cial im­pacts be­yond their tech­no­log­i­cal ap­pli­ca­tions.</p>
    <p>They must also learn how to in­te­grate and am­plify prin­ci­ples of benef­i­cence, fair­ness, jus­tice and trans­parency in their de­signs.</p>
    <p>At the Sin­ga­pore Univer­sity of Tech­nol­ogy and De­sign, we train our stu­dents to nav­i­gate the rich but also che­quered ter­rains of ethics. At the end of their first year, un­der­grad­u­ates are re­quired to take a manda­tory course on ethics as part of the Pro­fes­sional Prac­tice Pro­gramme.</p>
    <p>This course serves as a primer for more ad­vanced hu­man­i­ties, arts and so­cial sci­ences elec­tives on AI ethics from such di­verse dis­ci­plines as an­thro­pol­ogy, de­sign the­ory, his­tory and phi­los­o­phy.</p>
    <p>The aim is to con­tin­u­ously and pro­gres­sively but­tress stu­dents’ fa­mil­iar­ity with and un­der­stand­ing of ethics, so that they can be ready to take on the com­plex mo­ral chal­lenges pre­sented by AI prac­tices in their pro­fes­sional lives.</p>
    <p>COR­PO­RATE AC­COUNT­ABIL­ITY</p>
    <p>We must also com­ple­ment such ed­u­ca­tional in­ter­ven­tions by mov­ing de­ci­sively from AI ethics guide­lines to con­sid­er­ing reg­u­la­tions that hold tech­nol­ogy com­pa­nies ac­count­able to con­crete eth­i­cal stan­dards.</p>
    <p>For ex­am­ple, un­der Sin­ga­pore’s Re­source Sus­tain­abil­ity Act that in­tro­duced the Ex­tended</p>
    <p>Pro­ducer Re­spon­si­bil­ity ap­proach, elec­tri­cal and elec­tronic goods man­u­fac­tur­ers are now legally ob­li­gated to col­lect and treat the e-waste their prod­ucts gen­er­ate when they reach end-of-life.</p>
    <p>Sim­i­larly, tech­nol­ogy com­pa­nies should also be sub­ject to reg­u­la­tions gov­ern­ing car­bon foot­print thresh­olds for com­put­ing pro­cesses that power AI-driven so­lu­tions.</p>
    <p>The salu­tary dis­course around the prom­ise of AI must be grounded in a recog­ni­tion of the pos­si­ble harms it can wreak.</p>
    <p>While ethics teams and guide­lines are steps in the right di­rec­tion, they risk be­ing tram­pled upon in the race for tech­no­log­i­cal dom­i­na­tion. head of hu­man­i­ties, arts and so­cial sci­ences. Jef­frey Chan Kok Hui is as­sis­tant pro­fes­sor of de­sign the­ory and ethics. They are both fac­ulty mem­bers at the Sin­ga­pore Univer­sity of Tech­nol­ogy and De­sign.</p>

    <div>
        <picture>
            <img src="https://i.prcdn.co/img?regionKey=DPHl7ef9meAqq50rofZx3g%3d%3d" />
        </picture>
        <span role="byline">PHOTO: ISTOCKPHOT&#xAD;O</span>
        <p data-role="text">With the far-reach&#xAD;ing im&#xAD;pact that ar&#xAD;ti&#xAD;fi&#xAD;cial in&#xAD;tel&#xAD;li&#xAD;gence has on our ev&#xAD;ery&#xAD;day lives, com&#xAD;pa&#xAD;nies&#x2019; AI ethics teams bear the colos&#xAD;sal bur&#xAD;den of en&#xAD;sur&#xAD;ing that this tech&#xAD;nol&#xAD;ogy is safe and fair, say the writ&#xAD;ers.</p>
    </div>

</article>

<section>
    <h3><a href="/catalog/language/english">Newspapers in English</a></h3>
    <h3><a href="/catalog/country/singapore">Newspapers from Singapore</a></h3>
</section>

    </div>
    
    <p><a href="http://www.pressreader.com">© PressReader. All rights reserved.</a></p>

        <script>
            (function (i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                    (i[r].q = i[r].q || []).push(arguments);
                }, i[r].l = 1 * new Date();
                a = s.createElement(o), m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g;
                m.parentNode.insertBefore(a, m);
            })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
        </script>
        <script>
            ga('create', 'UA-44408245-1');
            ga('send', 'pageView');
        </script>
</body>
</html>
